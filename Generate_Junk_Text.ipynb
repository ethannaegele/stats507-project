{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to take a text input and randomly select junk to intersperse throughout the text. The junk will be randomly inserted between words.\n",
        "\n",
        "There will be two junk regimes to choose from. In the first regime, the junk is randomly chosen from a set of fake latin/greek sounding pseudowords.\n",
        "\n",
        "In the second regime, the junk is chosen from \"complete junk\": random strings of characters, essentially \"keyboard mashing\". These are random letters, numbers, underscores, hyphens, etc. all mixed together in a string."
      ],
      "metadata": {
        "id": "t1IorekpezfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCh_Nn51l1yY",
        "outputId": "32802177-ecea-492e-f0cf-f2c3ee4df3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Fz-GzPRahaFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShqfkRRPeo41"
      },
      "outputs": [],
      "source": [
        "\n",
        "JUNK_TOKENS_NUMERIC_MASH = tuple({\n",
        "    \"123\", \"456\", \"789\", \"101112\", \"333\",\n",
        "    \"elt\", \"aaaa\", \"bbbbb\",\n",
        "    \"yzyzyzyz\", \"gorggorggorg\", \"99zzyyaa\",\n",
        "    \"qxjx92a__pllqqq\", \"55m-ghq\", \"aaslkfd\",\n",
        "    \"qmplxz\", \"338\", \"qvnnxa\",\n",
        "    \"zlrp33\", \"mash_09\", \"rxxjpl\", \"qlqllqq\",\n",
        "    \"prax_7\", \"qxjx92a\", \"pllqqq\",\n",
        "    \"aaslkfdjdfj\", \"tmpshd\", \"nseg\",\n",
        "    \"retetetet\", \"yuiyuiyui\", \"ebg\", \"38u7zz\",\n",
        "    \"zz__aa\", \"vm00p\", \"rlrllrllr\",\n",
        "    \"zzqqmm22\", \"vvrraaxx\", \"nno0ppll\",\n",
        "    \"brrtzz44\", \"klxklxklx\", \"mprqzz09\",\n",
        "    \"xxyyzz8899\", \"qqqqpplm\", \"zzrraaqp\",\n",
        "    \"zmgxpl01\", \"gxpqrrn\", \"lmqqzz3\",\n",
        "    \"arx9z9z9\", \"zzoomm11\", \"jhqwxp77\",\n",
        "    \"fzznmm22\", \"xxlwwkq3\", \"pzxq88lm\",\n",
        "    \"zzzzjqpa\", \"mqx9nnq\", \"xplmrr00\",\n",
        "    \"kqqz0z0z\", \"rrxq99aa\", \"pllxxwq\",\n",
        "    \"dqzmmf91\", \"rnggll22\", \"wqxpzzl\",\n",
        "    \"zlkqp55\", \"mmzqrr8\", \"vxvxvz22\",\n",
        "    \"plmxy7q\", \"qzzoxxk\", \"rqm99zzy\",\n",
        "    \"lzzppq14\", \"xgqr00qs\", \"mzznplw4\",\n",
        "    \"znqx88aa\", \"qqzmrr02\", \"pplqz1z1\"\n",
        "})\n",
        "\n",
        "\n",
        "JUNK_TOKENS_PSEUDO = tuple({\n",
        "    \"amet\",\n",
        "    \"consectetur\", \"adipiscing\", \"thalion\", \"meridos\", \"kalethon\", \"doryne\",\n",
        "    \"pelaxis\", \"morathos\", \"serion\", \"valethis\", \"threnon\", \"kaesira\",\n",
        "    \"lorinon\", \"barathor\", \"melidon\", \"tarikos\", \"pharion\", \"silethra\",\n",
        "    \"orinthos\", \"varenes\", \"kalithra\", \"morinae\", \"lycrate\", \"helinon\",\n",
        "    \"dramis\", \"solithon\", \"perakis\", \"minorae\", \"tarinon\", \"silathos\",\n",
        "    \"verion\", \"korathe\", \"periostra\", \"kaligenis\", \"dorathium\", \"seraphele\",\n",
        "    \"thalionis\", \"varenthos\", \"melidonae\", \"lorinthum\", \"xenathra\",\n",
        "    \"phorinos\", \"veracalix\", \"mithareon\", \"torivalis\", \"dorithra\",\n",
        "    \"luminarae\", \"heliostrum\", \"parathion\", \"sarimora\", \"kalithium\",\n",
        "    \"morathion\",\n",
        "    \"thalimoros\",\n",
        "    \"xenarithos\",\n",
        "    \"moradrix\",\n",
        "    \"kalitheron\",\n",
        "    \"perionax\",\n",
        "    \"dorimethis\",\n",
        "    \"varalithos\",\n",
        "    \"serinthae\",\n",
        "    \"melaxiora\",\n",
        "    \"phorandis\",\n",
        "    \"loratheon\",\n",
        "    \"kaliserum\",\n",
        "    \"verathrix\",\n",
        "    \"moradion\",\n",
        "    \"dorexila\",\n",
        "    \"sariphon\",\n",
        "    \"thalexior\",\n",
        "    \"minarethus\",\n",
        "    \"helidrax\",\n",
        "    \"torinathae\",\n",
        "\n",
        "})\n",
        "\n",
        "JUNK_TOKENS_LATIN_GREEK = tuple({\"alpha\", \"beta\", \"gamma\", \"delta\", \"epsilon\", \"zeta\", \"eta\", \"theta\",\n",
        "    \"sigma\", \"pi\", \"psi\", \"phi\", \"kappa\", \"omega\", \"lorem\", \"ipsum\"})\n",
        "\n",
        "_DEFAULT_RNG = np.random.default_rng()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(JUNK_TOKENS_NUMERIC_MASH))\n",
        "print(len(JUNK_TOKENS_PSEUDO))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47w1G4ziDCN",
        "outputId": "63e49dff-5480-4787-adcc-31575bbd80ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73\n",
            "73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_junk(\n",
        "    text,\n",
        "    junk_type = \"mash\",\n",
        "    p = 0.25,\n",
        "    rng = None,\n",
        "    min_junk = 1,\n",
        "    max_junk = 3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Insert random junk tokens between words with probability p.\n",
        "    For each boundary chosen for insertion, insert random number of junk tokens\n",
        "    from min_junk to max_junk.\n",
        "    \"\"\"\n",
        "    jt = junk_type.strip().lower()\n",
        "    assert jt in {\"mash\", \"pseudo\"}\n",
        "\n",
        "    if jt == \"mash\":\n",
        "        junk_tokens = JUNK_TOKENS_NUMERIC_MASH\n",
        "    else:\n",
        "        junk_tokens = JUNK_TOKENS_PSEUDO\n",
        "\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    words = text.split()\n",
        "    n = len(words)\n",
        "\n",
        "\n",
        "    if n < 2 or p <= 0.0:\n",
        "        return text\n",
        "\n",
        "    if rng is None:\n",
        "        rng = _DEFAULT_RNG\n",
        "\n",
        "    # n-1 possible boundaries between words\n",
        "    n_boundaries = n - 1\n",
        "\n",
        "\n",
        "    boundary_mask = rng.random(n_boundaries) < p\n",
        "    n_insert_boundaries = int(boundary_mask.sum())\n",
        "\n",
        "\n",
        "    if n_insert_boundaries == 0:\n",
        "        return text\n",
        "\n",
        "    # for each True boundary, decide how many junk tokens to insert\n",
        "\n",
        "    counts_per_boundary = rng.integers(\n",
        "        min_junk, max_junk + 1, size=n_insert_boundaries\n",
        "    )\n",
        "    total_junk = int(counts_per_boundary.sum())\n",
        "\n",
        "\n",
        "    junk_indices = rng.integers(0, len(junk_tokens), size=total_junk)\n",
        "\n",
        "\n",
        "    out_len = n + total_junk\n",
        "    new_words = [None] * out_len\n",
        "\n",
        "    j = 0  # index in new_words\n",
        "    k = 0  # index into junk_indices\n",
        "    c = 0  # index into counts_per_boundary\n",
        "\n",
        "    for i, w in enumerate(words):\n",
        "        new_words[j] = w\n",
        "        j += 1\n",
        "\n",
        "        # insert junk after this word if boundary_mask[i] is True\n",
        "        if i < n_boundaries and boundary_mask[i]:\n",
        "            n_here = int(counts_per_boundary[c])\n",
        "            c += 1\n",
        "\n",
        "            # insert n_here junk tokens\n",
        "            for _ in range(n_here):\n",
        "                new_words[j] = junk_tokens[junk_indices[k]]\n",
        "                j += 1\n",
        "                k += 1\n",
        "\n",
        "    return \" \".join(new_words)\n"
      ],
      "metadata": {
        "id": "NPg8FrldqkRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_junk(\"this is my favourite game of all time and i miss it dearly i made most of my best friends playing this game\",\n",
        "         p = 0.2,\n",
        "         junk_type=\"pseudo\",\n",
        "         min_junk=5,\n",
        "         max_junk=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "adm_heeLoLDh",
        "outputId": "39a489b5-9378-4af2-bd63-bcc1b61e503e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is my favourite game of all seraphele morathion morinae varenes perakis minorae time and i miss it dearly i made most of my best kaesira meridos morathos helinon heliostrum torivalis luminarae melidon dorathium melidonae friends playing this game'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/GoEmotions-test.csv')"
      ],
      "metadata": {
        "id": "6Yla7PpcvI61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df.sample(n=10, random_state=42).reset_index()"
      ],
      "metadata": {
        "id": "9UM2TH8NwKRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(2025)\n",
        "\n",
        "df_small[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.50, rng=rng)\n",
        "    for t in df_small[\"Text\"].astype(str).values\n",
        "]\n"
      ],
      "metadata": {
        "id": "kxPuwbGqvH4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_small['NoisyText'][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKJfp_PywXjS",
        "outputId": "c68935e0-9d9b-472f-eb0b-7b12653ef6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best ebg sub ever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rng1 = np.random.default_rng(2025)\n",
        "rng2 = np.random.default_rng(2025)\n",
        "rng3 = np.random.default_rng(2025)\n",
        "rng4 = np.random.default_rng(2025)\n",
        "\n",
        "df_noise_10_1 = df.copy()\n",
        "df_noise_10_1[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.10, max_junk=1, rng=rng1)\n",
        "    for t in df_noise_10_1[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_20_2 = df.copy()\n",
        "df_noise_20_2[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.20, max_junk=2, rng=rng2)\n",
        "    for t in df_noise_20_2[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_30_2 = df.copy()\n",
        "df_noise_30_2[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.30, max_junk=2, rng=rng3)\n",
        "    for t in df_noise_30_2[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_40_3 = df.copy()\n",
        "df_noise_40_3[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.40, max_junk=3, rng=rng4)\n",
        "    for t in df_noise_40_3[\"Text\"].astype(str).values\n",
        "]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID7cqo6izPNT",
        "outputId": "b19be018-290f-4f8f-f807-658d94cbf13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 118 ms, sys: 0 ns, total: 118 ms\n",
            "Wall time: 125 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rng5 = np.random.default_rng(2025)\n",
        "rng6 = np.random.default_rng(2025)\n",
        "rng7 = np.random.default_rng(2025)\n",
        "rng8 = np.random.default_rng(2025)\n",
        "\n",
        "df_noise_pseudo_10_1 = df.copy()\n",
        "df_noise_pseudo_10_1[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.10, max_junk=1, junk_type = \"pseudo\", rng=rng5)\n",
        "    for t in df_noise_pseudo_10_1[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_pseudo_20_2 = df.copy()\n",
        "df_noise_pseudo_20_2[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.20, max_junk=2, junk_type = \"pseudo\", rng=rng6)\n",
        "    for t in df_noise_pseudo_20_2[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_pseudo_30_2 = df.copy()\n",
        "df_noise_pseudo_30_2[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.30, max_junk=2, junk_type = \"pseudo\", rng=rng7)\n",
        "    for t in df_noise_pseudo_30_2[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_pseudo_40_3 = df.copy()\n",
        "df_noise_pseudo_40_3[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.40, max_junk=3, junk_type = \"pseudo\", rng=rng8)\n",
        "    for t in df_noise_pseudo_40_3[\"Text\"].astype(str).values\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4nQ3cbnsQ_s",
        "outputId": "4b7acc94-cbb9-481c-ca8f-caac40cd3ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 77.6 ms, sys: 3.16 ms, total: 80.8 ms\n",
            "Wall time: 79.2 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rng9 = np.random.default_rng(2025)\n",
        "rng10 = np.random.default_rng(2025)\n",
        "\n",
        "df_noise_pseudo_5_1 = df.copy()\n",
        "df_noise_pseudo_5_1[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.05, max_junk=1, junk_type = \"pseudo\", rng=rng9)\n",
        "    for t in df_noise_pseudo_5_1[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_pseudo_20_1 = df.copy()\n",
        "df_noise_pseudo_20_1[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.2, max_junk=1, junk_type = \"pseudo\", rng=rng10)\n",
        "    for t in df_noise_pseudo_5_1[\"Text\"].astype(str).values\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRwpiJd9vdvV",
        "outputId": "0c6a1613-3194-4a0b-93f3-2413f34812e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 53.7 ms, sys: 5.45 ms, total: 59.1 ms\n",
            "Wall time: 90.2 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rng11 = np.random.default_rng(2025)\n",
        "rng12 = np.random.default_rng(2025)\n",
        "\n",
        "df_noise_mash_5_1 = df.copy()\n",
        "df_noise_mash_5_1[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.05, max_junk=1, junk_type = \"mash\", rng=rng11)\n",
        "    for t in df_noise_mash_5_1[\"Text\"].astype(str).values\n",
        "]\n",
        "\n",
        "df_noise_mash_20_1 = df.copy()\n",
        "df_noise_mash_20_1[\"NoisyText\"] = [\n",
        "    add_junk(t, p=0.2, max_junk=1, junk_type = \"mash\", rng=rng12)\n",
        "    for t in df_noise_mash_5_1[\"Text\"].astype(str).values\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WusalcqZxLgL",
        "outputId": "a4bf66d8-1d40-4ffc-a24b-c1cd0768fd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.7 ms, sys: 0 ns, total: 32.7 ms\n",
            "Wall time: 33.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_noise_10_1.to_csv('/content/drive/MyDrive/Colab_data/test_noise_mash_10_1.csv')\n",
        "df_noise_20_2.to_csv('/content/drive/MyDrive/Colab_data/test_noise_mash_20_2.csv')\n",
        "df_noise_30_2.to_csv('/content/drive/MyDrive/Colab_data/test_noise_mash_30_2.csv')\n",
        "df_noise_40_3.to_csv('/content/drive/MyDrive/Colab_data/test_noise_mash_40_3.csv')"
      ],
      "metadata": {
        "id": "ZsmrbyeX2nzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_noise_pseudo_10_1.to_csv('/content/drive/MyDrive/Colab_data/test_noise_pseudo_10_1.csv')\n",
        "df_noise_pseudo_20_2.to_csv('/content/drive/MyDrive/Colab_data/test_noise_pseudo_20_2.csv')\n",
        "df_noise_pseudo_30_2.to_csv('/content/drive/MyDrive/Colab_data/test_noise_pseudo_30_2.csv')\n",
        "df_noise_pseudo_40_3.to_csv('/content/drive/MyDrive/Colab_data/test_noise_pseudo_40_3.csv')"
      ],
      "metadata": {
        "id": "3GoJhnX_tDnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_noise_pseudo_5_1.to_csv('/content/drive/MyDrive/Colab_data/test_noise_pseudo_5_1.csv')\n",
        "df_noise_pseudo_20_1.to_csv('/content/drive/MyDrive/Colab_data/test_noise_pseudo_20_1.csv')"
      ],
      "metadata": {
        "id": "ZDNc4LxOxhoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_noise_mash_5_1.to_csv('/content/drive/MyDrive/Colab_data/test_noise_mash_5_1.csv')\n",
        "df_noise_mash_20_1.to_csv('/content/drive/MyDrive/Colab_data/test_noise_mash_20_1.csv')"
      ],
      "metadata": {
        "id": "_6hEE4mMxvWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}